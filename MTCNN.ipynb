{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if using all of the data\n",
    "# 'Face Images' contains both the cleaned FER2013 dataset and the cleaned CMU Face Images dataset\n",
    "df = pd.read_csv(\"Face Images.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if using only a subset of the data\n",
    "\n",
    "frac = pd.read_csv(\"Face Images.csv\").sample(frac=0.01)\n",
    "whole = pd.read_csv(\"Face Images.csv\")\n",
    "\n",
    "disgust = whole[whole.emotion == 1]\n",
    "frac = frac[frac.emotion != 1]\n",
    "df = pd.concat([frac, disgust]) # df is 25% of the whole dataset + the disgust samples not taken in the 25% (since there are so few, use all of them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, box):\n",
    "    # Input: image: np array of pixels (image) to crop\n",
    "    #        box: a dictionary returned by detect_faces() containing coordinates/width/height of the box outlining the detected face\n",
    "    # Output: an np array of pixels representing the cropped image\n",
    "    x, y, width, height = box[0], box[1], box[2], box[3] # x,y,w,h of the box containing a detected face\n",
    "    return image[y:y+height, x:x+width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image):\n",
    "    # Input: image: an np array of pixels\n",
    "    # Output: an np array representing the input image resized to 224x224 px\n",
    "    size = (224, 224)\n",
    "    return np.array(Image.fromarray(np.squeeze(image, axis=2)).resize(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified: 6.54 for MTCNN and saving the images\n",
    "#Original:\n",
    "\n",
    "# For each image in the df, use the mtcnn to detect the face, then crop the image to just the face portion, and then resize to a constant size of 224x224 px\n",
    "images = []\n",
    "count = 0\n",
    "detector = MTCNN()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    original_image = np.fromstring(row[\"pixels\"], dtype=int, sep=\" \").reshape(row[\"height\"], row[\"width\"], 1).astype(\"float32\")\n",
    "    img = np.tile(original_image, [1,1,3]) # this MTCNN library only works with colour images (imgs with 3 channels), but grayscale images have only 1 channel. This pads the img to make the image have 3 channels\n",
    "    output = detector.detect_faces(img)\n",
    "    if len(output) == 1: # 1 face detected\n",
    "        resized_image = resize_image(crop_image(original_image, output[0][\"box\"]))\n",
    "        images.append([row[\"emotion\"], resized_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a cropped image\n",
    "plt.imshow(np.array(images[7151][1]).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the images to the directory corresponding to their labels\n",
    "expressions = {0:\"Angry\", 1:\"Disgust\", 2:\"Fear\", 3:\"Happy\", 4:\"Sad\", 5:\"Surprise\", 6:\"Neutral\"}\n",
    "\n",
    "count = 0\n",
    "\n",
    "for image in images:\n",
    "    label = image[0]\n",
    "    pixels = image[1]\n",
    "\n",
    "    # convert pixels to Image class\n",
    "    im = Image.fromarray(pixels).convert('L')\n",
    "\n",
    "    # same image to the test directory\n",
    "    im.save(f\"Abcd Efghij/{expressions[label]}/img_{count}.jpg\", \"JPEG\")\n",
    "    count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
