{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info about LIME and more examples can be found here: https://github.com/marcotcr/lime/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/path/to/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('/path/to/xData.npy')\n",
    "y = np.load('/path/to/yData.npy')\n",
    "\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(img):\n",
    "    # LIME treats the input as 2D RGB images, so we  convert the img to grayscale here so that the image is compatible with the model\n",
    "    gray_img = rgb2gray(img).reshape(-1, 128, 128, 1) # Modify this to match the input shape for your model. The input for the one used to create this notebook was (128,128,1)\n",
    "    return model.predict(gray_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer.explain_instance(X[0].squeeze(), make_prediction, num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the explanation for a specific class/prediction (indicated by explanation.top_labels[X])\n",
    "# Green areas mark areas that contribute positively to predicting the specified class (important for predicting that class)\n",
    "# Red areas mark areas that contribute negatively to predicting the specified class (important for predicting that the image belongs to a different specific class, or important for predicting that the image does NOT belong to the specified class)\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, hide_rest=False)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot explanation weights onto a heatmap visualization so that importance of different regions can be compared to each other\n",
    "\n",
    "dict_heatmap = dict(explanation.local_exp[explanation.top_labels[0]])\n",
    "heatmap = np.vectorize(dict_heatmap.get)(explanation.segments) \n",
    "\n",
    "plt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
