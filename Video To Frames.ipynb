{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take unorganized folders of labelled video data and transform the clips into sequences of frames and organize them into folders according to the emotion depicted in the clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREMA-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = pd.read_csv(\"VideoDemographics.csv\") # provides info about each actor in the CREMA-D dataset by actor ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the demographics dataframe into a dictionary to easily access age & gender by actor id\n",
    "demographics_as_dict = demographics.set_index(\"ActorID\").T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path to all videos to be turned into frames\n",
    "files = glob.glob(\"crema-d\" + \"/**/*.flv\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_d_to_expected = {\"ANG\":\"Angry\", \"DIS\":\"Disgust\", \"FEA\":\"Fear\", \"HAP\":\"Happy\", \"SAD\":\"Sad\", \"NEU\":\"Neutral\"}\n",
    "expressions = {0:\"Angry\", 1:\"Disgust\", 2:\"Fear\", 3:\"Happy\", 4:\"Sad\", 5:\"Surprise\", 6:\"Neutral\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_videos = {\"Angry\":0, \"Disgust\":0, \"Fear\":0, \"Happy\":0, \"Sad\":0, \"Surprise\":0, \"Neutral\":0} # map emotion category to the number of videos already processed from this category\n",
    "\n",
    "for filepath in files:\n",
    "    split_path = filepath.split(\"\\\\\")[1].split(\"_\")\n",
    "\n",
    "    emotion = crema_d_to_expected[split_path[2]] # emotion depicted in the video\n",
    "    intensity = split_path[3][:-4] # intensity of the emotion \n",
    "    age = str(demographics_as_dict[int(split_path[0])][0]) # age of the actor\n",
    "    gender = \"M\" if demographics_as_dict[int(split_path[0])][1] == \"Male\" else \"F\" # gender of the actor\n",
    "\n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "    frame_num = 0\n",
    "    has_frames_left, frame = cap.read()\n",
    "\n",
    "    while(has_frames_left):\n",
    "        if not os.path.exists(f'Emotions/{emotion}/video_{num_videos[emotion]}_{gender}_{age}_{intensity}/'): # cv2 will not create the directory if it does not exist, it will just silently fail\n",
    "            os.makedirs(f'Emotions/{emotion}/video_{num_videos[emotion]}_{gender}_{age}_{intensity}/')\n",
    "        \n",
    "        cv2.imwrite(f'Emotions/{emotion}/video_{num_videos[emotion]}_{gender}_{age}_{intensity}/frame_{frame_num}.jpg', frame) \n",
    "        frame_num = frame_num + 1\n",
    "        has_frames_left, frame = cap.read()\n",
    "\n",
    "    if frame_num != 0: # video was successfully processed\n",
    "        num_videos[emotion] = num_videos[emotion] + 1\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for i in range(1, 25):\n",
    "    files_subset = glob.glob(f\"RAVDESS\\\\Video_Speech_Actor_{i}\\\\Actor_{i}\\\\\" + \"*.mp4\") if i >= 10 else glob.glob(f\"RAVDESS\\\\Video_Speech_Actor_0{i}\\\\Actor_0{i}\\\\\" + \"*.mp4\")\n",
    "    files.extend(files_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2878 video clips instead of 2880 because I had issues downloading 2 of the files\n",
    "\n",
    "2880 = 60 trials per actor X 2 modalities X 24 actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravdess_to_expected = {1:6, 2:6, 3:3, 4:4, 5:0, 6:2, 7:1, 8:5} # note: RAVDESS has an extra class for \"calm:2\" which we will classify as neutral for now\n",
    "expressions = {0:\"Angry\", 1:\"Disgust\", 2:\"Fear\", 3:\"Happy\", 4:\"Sad\", 5:\"Surprise\", 6:\"Neutral\"} \n",
    "\n",
    "num_videos = {\"Angry\":0, \"Disgust\":0, \"Fear\":0, \"Happy\":0, \"Sad\":0, \"Surprise\":0, \"Neutral\":0} # map emotion category to the number of videos already processed from this category\n",
    "\n",
    "for filepath in files:\n",
    "    emotion = expressions[ravdess_to_expected[int(filepath.split(\"\\\\\")[3].split(\"-\")[2])]] \n",
    "\n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "    frame_num = 0\n",
    "    has_frames_left, frame = cap.read()\n",
    "\n",
    "    while(has_frames_left):\n",
    "        if not os.path.exists(f'RAVDESS Frames/{emotion}/video_{num_videos[emotion]}/'): # cv2 will not create the directory if it does not exist, it will just silently fail\n",
    "            os.makedirs(f'RAVDESS Frames/{emotion}/video_{num_videos[emotion]}/')\n",
    "        \n",
    "        cv2.imwrite(f'RAVDESS Frames/{emotion}/video_{num_videos[emotion]}/frame_{frame_num}.jpg', frame) \n",
    "        frame_num = frame_num + 1\n",
    "        has_frames_left, frame = cap.read()\n",
    "\n",
    "    if frame_num != 0: # video was successfully processed\n",
    "        num_videos[emotion] = num_videos[emotion] + 1\n",
    "\n",
    "    cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
